{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "02-02-Transfer_Learning_InceptionResNetV2_and_U-Net.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iSC_QvKJ7zgN",
        "outputId": "f338402a-6cab-4d2c-bea9-a574411edc48"
      },
      "source": [
        "# !!! IGNORE THIS WHEN RUNNING IT ON YOUR MACHINE !!!\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!pwd\n",
        "import os\n",
        "root_dir = '/content/drive/MyDrive/IEEE-GRSS/mountpt/Dubai-Satellite-Imagery-Multiclass-Segmentation'\n",
        "os.chdir(root_dir)\n",
        "!pwd"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/My Drive/IEEE-GRSS/mountpt/Dubai-Satellite-Imagery-Multiclass-Segmentation\n",
            "/content/drive/MyDrive/IEEE-GRSS/mountpt/Dubai-Satellite-Imagery-Multiclass-Segmentation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_oGvhYGz7ZTw"
      },
      "source": [
        "# Dubai Satellite Imagery Multiclass Segmentation\n",
        "## InceptionResNetV2 and U-Net Model\n",
        "\n",
        "In this notebook, a model that uses the augmented dataset is trained and the results are analyzed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vONZe1hC7ZT8"
      },
      "source": [
        "# Installing & Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-12T12:43:19.819740Z",
          "iopub.status.busy": "2021-06-12T12:43:19.819413Z",
          "iopub.status.idle": "2021-06-12T12:43:26.240415Z",
          "shell.execute_reply": "2021-06-12T12:43:26.239548Z",
          "shell.execute_reply.started": "2021-06-12T12:43:19.819667Z"
        },
        "scrolled": true,
        "id": "04lzx4K-7ZT-"
      },
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import albumentations as A\n",
        "from IPython.display import SVG\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import os, re, sys, random, shutil, cv2\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam, Nadam\n",
        "from tensorflow.keras import applications, optimizers\n",
        "from tensorflow.keras.applications import InceptionResNetV2\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "from tensorflow.keras.utils import model_to_dot, plot_model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, CSVLogger, LearningRateScheduler\n",
        "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, ZeroPadding2D, Dropout"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-12T12:44:41.199799Z",
          "iopub.status.busy": "2021-06-12T12:44:41.199442Z",
          "iopub.status.idle": "2021-06-12T12:44:41.486345Z",
          "shell.execute_reply": "2021-06-12T12:44:41.485383Z",
          "shell.execute_reply.started": "2021-06-12T12:44:41.199762Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "l2R8dISV7ZUC",
        "outputId": "b629d6d0-69b6-42cc-fd9e-256c543ee38f"
      },
      "source": [
        "# initialize list of lists\n",
        "data = [[\"building\", \"60\", \"16\", \"152\"],\n",
        "        [\"land\", \"132\", \"41\", \"246\"],\n",
        "        [\"road\", \"110\", \"193\", \"228\"],\n",
        "        [\"vegetation\", \"254\", \"221\", \"58\"],\n",
        "        [\"water\", \"226\", \"169\", \"41\"],\n",
        "        [\"unlabeled\", \"155\", \"155\", \"155\"]]\n",
        "  \n",
        "# Create the pandas DataFrame\n",
        "class_dict_df = pd.DataFrame(data, columns = [\"name\", \"r\", \"g\", \"b\"])\n",
        "class_dict_df"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>r</th>\n",
              "      <th>g</th>\n",
              "      <th>b</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>building</td>\n",
              "      <td>60</td>\n",
              "      <td>16</td>\n",
              "      <td>152</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>land</td>\n",
              "      <td>132</td>\n",
              "      <td>41</td>\n",
              "      <td>246</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>road</td>\n",
              "      <td>110</td>\n",
              "      <td>193</td>\n",
              "      <td>228</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>vegetation</td>\n",
              "      <td>254</td>\n",
              "      <td>221</td>\n",
              "      <td>58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>water</td>\n",
              "      <td>226</td>\n",
              "      <td>169</td>\n",
              "      <td>41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>unlabeled</td>\n",
              "      <td>155</td>\n",
              "      <td>155</td>\n",
              "      <td>155</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         name    r    g    b\n",
              "0    building   60   16  152\n",
              "1        land  132   41  246\n",
              "2        road  110  193  228\n",
              "3  vegetation  254  221   58\n",
              "4       water  226  169   41\n",
              "5   unlabeled  155  155  155"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-12T12:44:41.488451Z",
          "iopub.status.busy": "2021-06-12T12:44:41.488104Z",
          "iopub.status.idle": "2021-06-12T12:44:41.498196Z",
          "shell.execute_reply": "2021-06-12T12:44:41.497408Z",
          "shell.execute_reply.started": "2021-06-12T12:44:41.488415Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQs_h0Uu7ZUE",
        "outputId": "929ab990-7250-462f-fbb3-2a39fd22b4fc"
      },
      "source": [
        "label_names= list(class_dict_df.name)\n",
        "label_codes = []\n",
        "r= np.asarray(class_dict_df.r)\n",
        "g= np.asarray(class_dict_df.g)\n",
        "b= np.asarray(class_dict_df.b)\n",
        "\n",
        "for i in range(len(class_dict_df)):\n",
        "    label_codes.append(tuple([r[i], g[i], b[i]]))\n",
        "    \n",
        "label_codes, label_names"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([('60', '16', '152'),\n",
              "  ('132', '41', '246'),\n",
              "  ('110', '193', '228'),\n",
              "  ('254', '221', '58'),\n",
              "  ('226', '169', '41'),\n",
              "  ('155', '155', '155')],\n",
              " ['building', 'land', 'road', 'vegetation', 'water', 'unlabeled'])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qh_6EF6G7ZUI"
      },
      "source": [
        "# Create Useful Label & Code Conversion Dictionaries\n",
        "\n",
        "These will be used for:\n",
        "\n",
        "* One hot encoding the mask labels for model training\n",
        "* Decoding the predicted labels for interpretation and visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-12T12:44:41.499849Z",
          "iopub.status.busy": "2021-06-12T12:44:41.499369Z",
          "iopub.status.idle": "2021-06-12T12:44:41.507477Z",
          "shell.execute_reply": "2021-06-12T12:44:41.506699Z",
          "shell.execute_reply.started": "2021-06-12T12:44:41.499813Z"
        },
        "id": "rp2Aychh7ZUJ"
      },
      "source": [
        "code2id = {v:k for k,v in enumerate(label_codes)}\n",
        "id2code = {k:v for k,v in enumerate(label_codes)}\n",
        "\n",
        "name2id = {v:k for k,v in enumerate(label_names)}\n",
        "id2name = {k:v for k,v in enumerate(label_names)}"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-12T12:44:41.509105Z",
          "iopub.status.busy": "2021-06-12T12:44:41.508708Z",
          "iopub.status.idle": "2021-06-12T12:44:41.517469Z",
          "shell.execute_reply": "2021-06-12T12:44:41.516610Z",
          "shell.execute_reply.started": "2021-06-12T12:44:41.509030Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlUJQ3s47ZUK",
        "outputId": "986e595f-2419-4225-dc06-558bfa0b99c7"
      },
      "source": [
        "id2code"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: ('60', '16', '152'),\n",
              " 1: ('132', '41', '246'),\n",
              " 2: ('110', '193', '228'),\n",
              " 3: ('254', '221', '58'),\n",
              " 4: ('226', '169', '41'),\n",
              " 5: ('155', '155', '155')}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-12T12:44:41.519281Z",
          "iopub.status.busy": "2021-06-12T12:44:41.518871Z",
          "iopub.status.idle": "2021-06-12T12:44:41.527127Z",
          "shell.execute_reply": "2021-06-12T12:44:41.526025Z",
          "shell.execute_reply.started": "2021-06-12T12:44:41.519223Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vynURbO7ZUL",
        "outputId": "9952e869-84f3-4650-ef3c-aa70dafead4a"
      },
      "source": [
        "id2name"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'building',\n",
              " 1: 'land',\n",
              " 2: 'road',\n",
              " 3: 'vegetation',\n",
              " 4: 'water',\n",
              " 5: 'unlabeled'}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "niUr92w27ZUO"
      },
      "source": [
        "# Define Functions for One Hot Encoding RGB Labels & Decoding Encoded Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-12T12:44:41.531272Z",
          "iopub.status.busy": "2021-06-12T12:44:41.530929Z",
          "iopub.status.idle": "2021-06-12T12:44:41.540461Z",
          "shell.execute_reply": "2021-06-12T12:44:41.539490Z",
          "shell.execute_reply.started": "2021-06-12T12:44:41.531248Z"
        },
        "id": "sVN1khCu7ZUP"
      },
      "source": [
        "def rgb_to_onehot(rgb_image, colormap = id2code):\n",
        "    '''Function to one hot encode RGB mask labels\n",
        "        Inputs: \n",
        "            rgb_image - image matrix (eg. 256 x 256 x 3 dimension numpy ndarray)\n",
        "            colormap - dictionary of color to label id\n",
        "        Output: One hot encoded image of dimensions (height x width x num_classes) where num_classes = len(colormap)\n",
        "    '''\n",
        "    num_classes = len(colormap)\n",
        "    shape = rgb_image.shape[:2]+(num_classes,)\n",
        "    encoded_image = np.zeros( shape, dtype=np.int8 )\n",
        "    for i, cls in enumerate(colormap):\n",
        "        encoded_image[:,:,i] = np.all(rgb_image.reshape( (-1,3) ) == colormap[i])\n",
        "        encoded_image = encoded_image.reshape(shape[:3])\n",
        "    return encoded_image\n",
        "\n",
        "\n",
        "def onehot_to_rgb(onehot, colormap = id2code):\n",
        "    '''Function to decode encoded mask labels\n",
        "        Inputs: \n",
        "            onehot - one hot encoded image matrix (height x width x num_classes)\n",
        "            colormap - dictionary of color to label id\n",
        "        Output: Decoded RGB image (height x width x 3) \n",
        "    '''\n",
        "    single_layer = np.argmax(onehot, axis=-1)\n",
        "    output = np.zeros( onehot.shape[:2]+(3,) )\n",
        "    for k in colormap.keys():\n",
        "        output[single_layer==k] = colormap[k]\n",
        "    return np.uint8(output)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iADUfqjB7ZUQ"
      },
      "source": [
        "# Creating Custom Image Data Generators\n",
        "## Defining Data Generators"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-12T12:44:41.543833Z",
          "iopub.status.busy": "2021-06-12T12:44:41.543522Z",
          "iopub.status.idle": "2021-06-12T12:44:41.553325Z",
          "shell.execute_reply": "2021-06-12T12:44:41.552496Z",
          "shell.execute_reply.started": "2021-06-12T12:44:41.543802Z"
        },
        "id": "QJ2FqWkg7ZUR"
      },
      "source": [
        "# Normalizing only frame images, since masks contain label info\n",
        "data_gen_args = dict(rescale=1./255)\n",
        "mask_gen_args = dict()\n",
        "\n",
        "train_frames_datagen = ImageDataGenerator(**data_gen_args)\n",
        "train_masks_datagen = ImageDataGenerator(**mask_gen_args)\n",
        "val_frames_datagen = ImageDataGenerator(**data_gen_args)\n",
        "val_masks_datagen = ImageDataGenerator(**mask_gen_args)\n",
        "\n",
        "# Seed defined for aligning images and their masks\n",
        "seed = 1"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CIziwKbD7ZUS"
      },
      "source": [
        "# Custom Image Data Generators for Creating Batches of Frames and Masks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-12T12:44:41.556573Z",
          "iopub.status.busy": "2021-06-12T12:44:41.556291Z",
          "iopub.status.idle": "2021-06-12T12:44:41.568528Z",
          "shell.execute_reply": "2021-06-12T12:44:41.567762Z",
          "shell.execute_reply.started": "2021-06-12T12:44:41.556551Z"
        },
        "id": "iuH_kJVv7ZUT"
      },
      "source": [
        "def TrainAugmentGenerator(train_images_dir, train_masks_dir, seed = 1, batch_size = 8, target_size = (512, 512)):\n",
        "    '''Train Image data generator\n",
        "        Inputs: \n",
        "            seed - seed provided to the flow_from_directory function to ensure aligned data flow\n",
        "            batch_size - number of images to import at a time\n",
        "            train_images_dir - train images directory\n",
        "            train_masks_dir - train masks directory\n",
        "            target_size - tuple of integers (height, width)\n",
        "            \n",
        "        Output: Decoded RGB image (height x width x 3) \n",
        "    '''\n",
        "    train_image_generator = train_frames_datagen.flow_from_directory(\n",
        "    train_images_dir,\n",
        "    batch_size = batch_size, \n",
        "    seed = seed, \n",
        "    target_size = target_size)\n",
        "\n",
        "    train_mask_generator = train_masks_datagen.flow_from_directory(\n",
        "    train_masks_dir,\n",
        "    batch_size = batch_size, \n",
        "    seed = seed, \n",
        "    target_size = target_size)\n",
        "\n",
        "    while True:\n",
        "        X1i = train_image_generator.next()\n",
        "        X2i = train_mask_generator.next()\n",
        "                \n",
        "        #One hot encoding RGB images\n",
        "        mask_encoded = []\n",
        "        for x in range(X2i[0].shape[0]):   \n",
        "          mask_encoded.append(rgb_to_onehot(X2i[0][x,:,:,:], id2code)) \n",
        "        \n",
        "        yield X1i[0], np.asarray(mask_encoded)\n",
        "\n",
        "def ValAugmentGenerator(val_images_dir, val_masks_dir, seed = 1, batch_size = 8, target_size = (512, 512)):\n",
        "    '''Validation Image data generator\n",
        "        Inputs: \n",
        "            seed - seed provided to the flow_from_directory function to ensure aligned data flow\n",
        "            batch_size - number of images to import at a time\n",
        "            val_images_dir - validation images directory\n",
        "            val_masks_dir - validation masks directory\n",
        "            target_size - tuple of integers (height, width)\n",
        "            \n",
        "        Output: Decoded RGB image (height x width x 3) \n",
        "    '''\n",
        "    val_image_generator = val_frames_datagen.flow_from_directory(\n",
        "    val_images_dir,\n",
        "    batch_size = batch_size, \n",
        "    seed = seed, \n",
        "    target_size = target_size)\n",
        "\n",
        "\n",
        "    val_mask_generator = val_masks_datagen.flow_from_directory(\n",
        "    val_masks_dir,\n",
        "    batch_size = batch_size, \n",
        "    seed = seed, \n",
        "    target_size = target_size)\n",
        "\n",
        "\n",
        "    while True:\n",
        "        X1i = val_image_generator.next()\n",
        "        X2i = val_mask_generator.next()\n",
        "        \n",
        "        #One hot encoding RGB images\n",
        "        mask_encoded = [rgb_to_onehot(X2i[0][x,:,:,:], id2code) for x in range(X2i[0].shape[0])]\n",
        "        \n",
        "        yield X1i[0], np.asarray(mask_encoded)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5AF4SyB7ZUU"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFEITi6N7ZUW"
      },
      "source": [
        "train_images = \"./Augmented_data/train_images/\"\n",
        "train_masks = \"./Augmented_data/train_masks/\"\n",
        "val_images = \"./Augmented_data/val_images/\"\n",
        "val_masks = \"./Augmented_data/val_masks/\"\n",
        "aug_train_images = \"./Augmented_data/aug_train_images/\"\n",
        "aug_train_masks = \"./Augmented_data/aug_train_masks/\""
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-12T12:44:41.570126Z",
          "iopub.status.busy": "2021-06-12T12:44:41.569658Z",
          "iopub.status.idle": "2021-06-12T12:44:41.594841Z",
          "shell.execute_reply": "2021-06-12T12:44:41.594124Z",
          "shell.execute_reply.started": "2021-06-12T12:44:41.570089Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "X5SpmOjs7ZUY",
        "outputId": "89d219c4-2885-4ded-e5ab-0d99c81b2457"
      },
      "source": [
        "batch_size = 16\n",
        "num_train_samples = len(np.sort(os.listdir(train_images)))\n",
        "num_val_samples = len(np.sort(os.listdir(val_images)))\n",
        "steps_per_epoch = np.ceil(float(num_train_samples) / float(batch_size))\n",
        "print('steps_per_epoch: ', steps_per_epoch)\n",
        "validation_steps = np.ceil(float(4 * num_val_samples) / float(batch_size))\n",
        "print('validation_steps: ', validation_steps)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-54487e78edd8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnum_train_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mnum_val_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msteps_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_train_samples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'steps_per_epoch: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './Augmented_data/train_images/'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9EfPIB07ZUZ"
      },
      "source": [
        "## InceptionResNetV2 UNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-12T12:44:41.597651Z",
          "iopub.status.busy": "2021-06-12T12:44:41.597421Z",
          "iopub.status.idle": "2021-06-12T12:44:41.608551Z",
          "shell.execute_reply": "2021-06-12T12:44:41.607692Z",
          "shell.execute_reply.started": "2021-06-12T12:44:41.597629Z"
        },
        "id": "9JiioENv7ZUa"
      },
      "source": [
        "def conv_block(input, num_filters):\n",
        "    x = Conv2D(num_filters, 3, padding=\"same\")(input)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "def decoder_block(input, skip_features, num_filters):\n",
        "    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(input)\n",
        "    x = Concatenate()([x, skip_features])\n",
        "    x = conv_block(x, num_filters)\n",
        "    return x\n",
        "\n",
        "def build_inception_resnetv2_unet(input_shape):\n",
        "    \"\"\" Input \"\"\"\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    \"\"\" Pre-trained InceptionResNetV2 Model \"\"\"\n",
        "    encoder = InceptionResNetV2(include_top=False, weights=\"imagenet\", input_tensor=inputs)\n",
        "\n",
        "    \"\"\" Encoder \"\"\"\n",
        "    s1 = encoder.get_layer(\"input_1\").output           ## (512 x 512)\n",
        "\n",
        "    s2 = encoder.get_layer(\"activation\").output        ## (255 x 255)\n",
        "    s2 = ZeroPadding2D(( (1, 0), (1, 0) ))(s2)         ## (256 x 256)\n",
        "\n",
        "    s3 = encoder.get_layer(\"activation_3\").output      ## (126 x 126)\n",
        "    s3 = ZeroPadding2D((1, 1))(s3)                     ## (128 x 128)\n",
        "\n",
        "    s4 = encoder.get_layer(\"activation_74\").output      ## (61 x 61)\n",
        "    s4 = ZeroPadding2D(( (2, 1),(2, 1) ))(s4)           ## (64 x 64)\n",
        "\n",
        "    \"\"\" Bridge \"\"\"\n",
        "    b1 = encoder.get_layer(\"activation_161\").output     ## (30 x 30)\n",
        "    b1 = ZeroPadding2D((1, 1))(b1)                      ## (32 x 32)\n",
        "\n",
        "    \"\"\" Decoder \"\"\"\n",
        "    d1 = decoder_block(b1, s4, 512)                     ## (64 x 64)\n",
        "    d2 = decoder_block(d1, s3, 256)                     ## (128 x 128)\n",
        "    d3 = decoder_block(d2, s2, 128)                     ## (256 x 256)\n",
        "    d4 = decoder_block(d3, s1, 64)                      ## (512 x 512)\n",
        "    \n",
        "    \"\"\" Output \"\"\"\n",
        "    dropout = Dropout(0.3)(d4)\n",
        "    outputs = Conv2D(6, 1, padding=\"same\", activation=\"softmax\")(dropout)\n",
        "\n",
        "    model = Model(inputs, outputs, name=\"InceptionResNetV2-UNet\")\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-12T12:44:41.610347Z",
          "iopub.status.busy": "2021-06-12T12:44:41.609790Z",
          "iopub.status.idle": "2021-06-12T12:44:57.214662Z",
          "shell.execute_reply": "2021-06-12T12:44:57.213862Z",
          "shell.execute_reply.started": "2021-06-12T12:44:41.610297Z"
        },
        "id": "w6RJXYKS7ZUa"
      },
      "source": [
        "K.clear_session()\n",
        "\n",
        "def dice_coef(y_true, y_pred):\n",
        "    return (2. * K.sum(y_true * y_pred) + 1.) / (K.sum(y_true) + K.sum(y_pred) + 1.)\n",
        "\n",
        "model = build_inception_resnetv2_unet(input_shape = (512, 512, 3))\n",
        "model.compile(optimizer=Adam(lr = 0.0001), loss='categorical_crossentropy', metrics=[dice_coef, \"accuracy\"])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-12T12:45:04.210745Z",
          "iopub.status.busy": "2021-06-12T12:45:04.210235Z",
          "iopub.status.idle": "2021-06-12T12:45:04.219042Z",
          "shell.execute_reply": "2021-06-12T12:45:04.218335Z",
          "shell.execute_reply.started": "2021-06-12T12:45:04.210705Z"
        },
        "id": "1zvFSiLW7ZUb"
      },
      "source": [
        "def exponential_decay(lr0, s):\n",
        "    def exponential_decay_fn(epoch):\n",
        "        return lr0 * 0.1 **(epoch / s)\n",
        "    return exponential_decay_fn\n",
        "\n",
        "exponential_decay_fn = exponential_decay(0.0001, 60)\n",
        "\n",
        "lr_scheduler = LearningRateScheduler(\n",
        "    exponential_decay_fn,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "checkpoint = ModelCheckpoint(\n",
        "    filepath = 'InceptionResNetV2-UNet.h5',\n",
        "    save_best_only = True, \n",
        "#     save_weights_only = False,\n",
        "    monitor = 'val_loss', \n",
        "    mode = 'auto', \n",
        "    verbose = 1\n",
        ")\n",
        "\n",
        "earlystop = EarlyStopping(\n",
        "    monitor = 'val_loss', \n",
        "    min_delta = 0.001, \n",
        "    patience = 12, \n",
        "    mode = 'auto', \n",
        "    verbose = 1,\n",
        "    restore_best_weights = True\n",
        ")\n",
        "\n",
        "csvlogger = CSVLogger(\n",
        "    filename= \"model_training.csv\",\n",
        "    separator = \",\",\n",
        "    append = False\n",
        ")\n",
        "\n",
        "callbacks = [\n",
        "             checkpoint, \n",
        "             earlystop, \n",
        "             csvlogger, \n",
        "             lr_scheduler,\n",
        "             keras.callbacks.ModelCheckpoint(\n",
        "                os.path.join(\"./weights\", \"weights.02-data-aug.{epoch:03d}.hdf5\"), \n",
        "                save_best_only=False,\n",
        "                save_weights_only=True\n",
        "              ),\n",
        "            ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zre3voov7ZUb"
      },
      "source": [
        "train_images = \"./Augmented_data/train_images/\"\n",
        "train_masks = \"./Augmented_data/train_masks/\"\n",
        "val_images = \"./Augmented_data/val_images/\"\n",
        "val_masks = \"./Augmented_data/val_masks/\"\n",
        "aug_train_images = \"./Augmented_data/aug_train_images/\"\n",
        "aug_train_masks = \"./Augmented_data/aug_train_masks/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-12T12:45:04.220698Z",
          "iopub.status.busy": "2021-06-12T12:45:04.220201Z",
          "iopub.status.idle": "2021-06-12T13:12:27.495364Z",
          "shell.execute_reply": "2021-06-12T13:12:27.494446Z",
          "shell.execute_reply.started": "2021-06-12T12:45:04.220666Z"
        },
        "id": "-henUK-q7ZUc"
      },
      "source": [
        "history = model.fit(\n",
        "    TrainAugmentGenerator(train_images_dir = train_images, train_masks_dir = train_masks, target_size = (512, 512)), \n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    validation_data = ValAugmentGenerator(val_images_dir = val_images, val_masks_dir = val_masks, target_size = (512, 512)), \n",
        "    validation_steps = validation_steps, \n",
        "    epochs = 50,\n",
        "    callbacks=callbacks,\n",
        "    use_multiprocessing=False,\n",
        "    verbose=1\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-12T13:13:18.334722Z",
          "iopub.status.busy": "2021-06-12T13:13:18.334406Z",
          "iopub.status.idle": "2021-06-12T13:13:18.364837Z",
          "shell.execute_reply": "2021-06-12T13:13:18.363949Z",
          "shell.execute_reply.started": "2021-06-12T13:13:18.334692Z"
        },
        "id": "558GZz3D7ZUc"
      },
      "source": [
        "df_result = pd.DataFrame(history.history)\n",
        "df_result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-12T13:13:31.838947Z",
          "iopub.status.busy": "2021-06-12T13:13:31.838639Z",
          "iopub.status.idle": "2021-06-12T13:13:33.160782Z",
          "shell.execute_reply": "2021-06-12T13:13:33.159969Z",
          "shell.execute_reply.started": "2021-06-12T13:13:31.838918Z"
        },
        "id": "4VwtzUEM7ZUd"
      },
      "source": [
        "fig, ax = plt.subplots(1, 4, figsize=(40, 5))\n",
        "ax = ax.ravel()\n",
        "metrics = ['Dice Coefficient', 'Accuracy', 'Loss', 'Learning Rate']\n",
        "\n",
        "for i, met in enumerate(['dice_coef', 'accuracy', 'loss', 'lr']): \n",
        "    if met != 'lr':\n",
        "        ax[i].plot(history.history[met])\n",
        "        ax[i].plot(history.history['val_' + met])\n",
        "        ax[i].set_title('{} vs Epochs'.format(metrics[i]), fontsize=16)\n",
        "        ax[i].set_xlabel('Epochs')\n",
        "        ax[i].set_ylabel(metrics[i])\n",
        "        ax[i].set_xticks(np.arange(0,45,4))\n",
        "        ax[i].legend(['Train', 'Validation'])\n",
        "        ax[i].xaxis.grid(True, color = \"lightgray\", linewidth = \"0.8\", linestyle = \"-\")\n",
        "        ax[i].yaxis.grid(True, color = \"lightgray\", linewidth = \"0.8\", linestyle = \"-\")\n",
        "    else:\n",
        "        ax[i].plot(history.history[met])\n",
        "        ax[i].set_title('{} vs Epochs'.format(metrics[i]), fontsize=16)\n",
        "        ax[i].set_xlabel('Epochs')\n",
        "        ax[i].set_ylabel(metrics[i])\n",
        "        ax[i].set_xticks(np.arange(0,45,4))\n",
        "        ax[i].xaxis.grid(True, color = \"lightgray\", linewidth = \"0.8\", linestyle = \"-\")\n",
        "        ax[i].yaxis.grid(True, color = \"lightgray\", linewidth = \"0.8\", linestyle = \"-\")\n",
        "        \n",
        "plt.savefig('model_metrics_plot.png', facecolor= 'w',transparent= False, bbox_inches= 'tight', dpi= 150)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-12T13:13:46.913592Z",
          "iopub.status.busy": "2021-06-12T13:13:46.913217Z",
          "iopub.status.idle": "2021-06-12T13:13:47.575906Z",
          "shell.execute_reply": "2021-06-12T13:13:47.574996Z",
          "shell.execute_reply.started": "2021-06-12T13:13:46.913558Z"
        },
        "id": "7-fASnAd7ZUd"
      },
      "source": [
        "model.load_weights(\"./InceptionResNetV2-UNet.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-12T13:13:49.803300Z",
          "iopub.status.busy": "2021-06-12T13:13:49.802979Z",
          "iopub.status.idle": "2021-06-12T13:13:49.807561Z",
          "shell.execute_reply": "2021-06-12T13:13:49.806527Z",
          "shell.execute_reply.started": "2021-06-12T13:13:49.803268Z"
        },
        "id": "24TuwpLA7ZUe"
      },
      "source": [
        "testing_gen = ValAugmentGenerator(val_images_dir = val_images, val_masks_dir = val_masks, target_size = (512, 512))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-12T13:13:52.475118Z",
          "iopub.status.busy": "2021-06-12T13:13:52.474726Z",
          "iopub.status.idle": "2021-06-12T13:13:53.261302Z",
          "shell.execute_reply": "2021-06-12T13:13:53.259984Z",
          "shell.execute_reply.started": "2021-06-12T13:13:52.475084Z"
        },
        "id": "XZ5B1f4C7ZUe"
      },
      "source": [
        "!mkdir predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-12T13:13:58.579323Z",
          "iopub.status.busy": "2021-06-12T13:13:58.578977Z",
          "iopub.status.idle": "2021-06-12T13:14:32.639374Z",
          "shell.execute_reply": "2021-06-12T13:14:32.638256Z",
          "shell.execute_reply.started": "2021-06-12T13:13:58.579274Z"
        },
        "id": "yJGzweon7ZUf"
      },
      "source": [
        "count = 0\n",
        "for i in range(2):\n",
        "    batch_img,batch_mask = next(testing_gen)\n",
        "    pred_all= model.predict(batch_img)\n",
        "    np.shape(pred_all)\n",
        "    \n",
        "    for j in range(0,np.shape(pred_all)[0]):\n",
        "        count += 1\n",
        "        fig = plt.figure(figsize=(20,8))\n",
        "\n",
        "        ax1 = fig.add_subplot(1,3,1)\n",
        "        ax1.imshow(batch_img[j])\n",
        "        ax1.set_title('Input Image', fontdict={'fontsize': 16, 'fontweight': 'medium'})\n",
        "        ax1.grid(False)\n",
        "\n",
        "        ax2 = fig.add_subplot(1,3,2)\n",
        "        ax2.set_title('Ground Truth Mask', fontdict={'fontsize': 16, 'fontweight': 'medium'})\n",
        "        ax2.imshow(onehot_to_rgb(batch_mask[j],id2code))\n",
        "        ax2.grid(False)\n",
        "\n",
        "        ax3 = fig.add_subplot(1,3,3)\n",
        "        ax3.set_title('Predicted Mask', fontdict={'fontsize': 16, 'fontweight': 'medium'})\n",
        "        ax3.imshow(onehot_to_rgb(pred_all[j],id2code))\n",
        "        ax3.grid(False)\n",
        "\n",
        "        plt.savefig('./predictions/prediction_{}.png'.format(count), facecolor= 'w', transparent= False, bbox_inches= 'tight', dpi= 200)\n",
        "        plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-12T13:15:17.880332Z",
          "iopub.status.busy": "2021-06-12T13:15:17.879986Z",
          "iopub.status.idle": "2021-06-12T13:15:18.564835Z",
          "shell.execute_reply": "2021-06-12T13:15:18.563760Z",
          "shell.execute_reply.started": "2021-06-12T13:15:17.880278Z"
        },
        "id": "-SRcx0at7ZUf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}